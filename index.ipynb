{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Our Data - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "\n",
    "In this lab we'll perform a full linear regression on our data. We'll take a stepwise approach and we'll try to improve our model as we go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "You will be able to:\n",
    "\n",
    "* Remove predictors with p-values too high and refit the model\n",
    "* Examine and interpret the model results\n",
    "* Split data into training and testing sets\n",
    "* Fit a regression model to the data set using statsmodel library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build single linear regression models\n",
    "\n",
    "From the previous steps, it is pretty clear that we have quite a few predictors, but there are some issues with them. Linearity with the target \"Weekly_Sales\" wasn't apparent. If that's the case, it's always smart to start small, and go ahead and build linear regression models with just one input at the time. Somewhat like what we've done in section 10, let's look at some statistics for single linear regression models for all our *continuous* variables with the outcome.\n",
    "\n",
    "**Note: for now, we will not use holdout validation, as we're just trying to gauge interpretation and a sense of predictive capacity for each of the candidate predictors**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the cleaned dataset \"walmart_dataset.csv\", and check its contents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('walmart_dataset_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pull up the info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 97839 entries, 0 to 97838\n",
      "Columns: 127 entries, Weekly_Sales to binned_markdown_5_NaN\n",
      "dtypes: bool(1), float64(6), int64(120)\n",
      "memory usage: 94.1 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the output for info is much smaller compared to what we usually see. Because we have so many columns, pandas is intentionally not showing the data types for each column. Let's use `info()` again, but now just on the first 15 columns of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 97839 entries, 0 to 97838\n",
      "Data columns (total 15 columns):\n",
      "Weekly_Sales    97839 non-null float64\n",
      "IsHoliday       97839 non-null bool\n",
      "Size            97839 non-null float64\n",
      "Temperature     97839 non-null float64\n",
      "Fuel_Price      97839 non-null float64\n",
      "CPI             97839 non-null float64\n",
      "Unemployment    97839 non-null float64\n",
      "Store_1         97839 non-null int64\n",
      "Store_10        97839 non-null int64\n",
      "Store_2         97839 non-null int64\n",
      "Store_3         97839 non-null int64\n",
      "Store_4         97839 non-null int64\n",
      "Store_5         97839 non-null int64\n",
      "Store_6         97839 non-null int64\n",
      "Store_7         97839 non-null int64\n",
      "dtypes: bool(1), float64(6), int64(8)\n",
      "memory usage: 10.5 MB\n"
     ]
    }
   ],
   "source": [
    "df[df.columns[0:15]].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that all the columns from store_1 onwards are actually dummies, so categorical variables. Because we stored the data and loaded it in again, this information was lost. Let's make sure they become categorical again. You can write a for-loop to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,11):\n",
    "    df['Store_' + str(i)] = pd.cut(df['Store_' +str(i)], bins = 2, labels = ['0','1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure IsHoliday is a categorical variable as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.IsHoliday = pd.cut(df.IsHoliday, bins = 2, labels = ['False', 'True'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the info again to make sure everything is OK now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 97839 entries, 0 to 97838\n",
      "Data columns (total 15 columns):\n",
      "Weekly_Sales    97839 non-null float64\n",
      "IsHoliday       97839 non-null category\n",
      "Size            97839 non-null float64\n",
      "Temperature     97839 non-null float64\n",
      "Fuel_Price      97839 non-null float64\n",
      "CPI             97839 non-null float64\n",
      "Unemployment    97839 non-null float64\n",
      "Store_1         97839 non-null category\n",
      "Store_10        97839 non-null category\n",
      "Store_2         97839 non-null category\n",
      "Store_3         97839 non-null category\n",
      "Store_4         97839 non-null category\n",
      "Store_5         97839 non-null category\n",
      "Store_6         97839 non-null category\n",
      "Store_7         97839 non-null category\n",
      "dtypes: category(9), float64(6)\n",
      "memory usage: 5.3 MB\n"
     ]
    }
   ],
   "source": [
    "df[df.columns[0:15]].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! you should see that the datatypes have changed to categories now! If you use `.describe` now, you should see only the remaining continuous variables in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Size</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>97839.000000</td>\n",
       "      <td>9.783900e+04</td>\n",
       "      <td>9.783900e+04</td>\n",
       "      <td>9.783900e+04</td>\n",
       "      <td>9.783900e+04</td>\n",
       "      <td>9.783900e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17223.235591</td>\n",
       "      <td>-8.044340e-14</td>\n",
       "      <td>2.339480e-13</td>\n",
       "      <td>4.784098e-13</td>\n",
       "      <td>-9.181116e-15</td>\n",
       "      <td>1.795967e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>25288.572553</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1098.000000</td>\n",
       "      <td>-1.611999e+00</td>\n",
       "      <td>-3.843452e+00</td>\n",
       "      <td>-1.691961e+00</td>\n",
       "      <td>-1.958762e+00</td>\n",
       "      <td>-2.776898e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2336.485000</td>\n",
       "      <td>-1.028620e+00</td>\n",
       "      <td>-7.087592e-01</td>\n",
       "      <td>-1.053793e+00</td>\n",
       "      <td>-1.266966e-01</td>\n",
       "      <td>-6.503157e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7658.280000</td>\n",
       "      <td>2.834360e-01</td>\n",
       "      <td>1.340726e-01</td>\n",
       "      <td>1.180741e-01</td>\n",
       "      <td>4.995210e-01</td>\n",
       "      <td>-4.621274e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>20851.275000</td>\n",
       "      <td>1.113495e+00</td>\n",
       "      <td>8.680410e-01</td>\n",
       "      <td>8.243739e-01</td>\n",
       "      <td>6.346144e-01</td>\n",
       "      <td>7.089160e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>693099.360000</td>\n",
       "      <td>1.171380e+00</td>\n",
       "      <td>1.738375e+00</td>\n",
       "      <td>2.745691e+00</td>\n",
       "      <td>8.517705e-01</td>\n",
       "      <td>2.361469e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Weekly_Sales          Size   Temperature    Fuel_Price           CPI  \\\n",
       "count   97839.000000  9.783900e+04  9.783900e+04  9.783900e+04  9.783900e+04   \n",
       "mean    17223.235591 -8.044340e-14  2.339480e-13  4.784098e-13 -9.181116e-15   \n",
       "std     25288.572553  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min     -1098.000000 -1.611999e+00 -3.843452e+00 -1.691961e+00 -1.958762e+00   \n",
       "25%      2336.485000 -1.028620e+00 -7.087592e-01 -1.053793e+00 -1.266966e-01   \n",
       "50%      7658.280000  2.834360e-01  1.340726e-01  1.180741e-01  4.995210e-01   \n",
       "75%     20851.275000  1.113495e+00  8.680410e-01  8.243739e-01  6.346144e-01   \n",
       "max    693099.360000  1.171380e+00  1.738375e+00  2.745691e+00  8.517705e-01   \n",
       "\n",
       "       Unemployment  \n",
       "count  9.783900e+04  \n",
       "mean   1.795967e-12  \n",
       "std    1.000000e+00  \n",
       "min   -2.776898e+00  \n",
       "25%   -6.503157e-01  \n",
       "50%   -4.621274e-02  \n",
       "75%    7.089160e-01  \n",
       "max    2.361469e+00  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.columns[0:15]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Size</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24924.50</td>\n",
       "      <td>0.283436</td>\n",
       "      <td>-1.301205</td>\n",
       "      <td>-1.56024</td>\n",
       "      <td>0.40349</td>\n",
       "      <td>0.913194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50605.27</td>\n",
       "      <td>0.283436</td>\n",
       "      <td>-1.301205</td>\n",
       "      <td>-1.56024</td>\n",
       "      <td>0.40349</td>\n",
       "      <td>0.913194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13740.12</td>\n",
       "      <td>0.283436</td>\n",
       "      <td>-1.301205</td>\n",
       "      <td>-1.56024</td>\n",
       "      <td>0.40349</td>\n",
       "      <td>0.913194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39954.04</td>\n",
       "      <td>0.283436</td>\n",
       "      <td>-1.301205</td>\n",
       "      <td>-1.56024</td>\n",
       "      <td>0.40349</td>\n",
       "      <td>0.913194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32229.38</td>\n",
       "      <td>0.283436</td>\n",
       "      <td>-1.301205</td>\n",
       "      <td>-1.56024</td>\n",
       "      <td>0.40349</td>\n",
       "      <td>0.913194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Weekly_Sales      Size  Temperature  Fuel_Price      CPI  Unemployment\n",
       "0      24924.50  0.283436    -1.301205    -1.56024  0.40349      0.913194\n",
       "1      50605.27  0.283436    -1.301205    -1.56024  0.40349      0.913194\n",
       "2      13740.12  0.283436    -1.301205    -1.56024  0.40349      0.913194\n",
       "3      39954.04  0.283436    -1.301205    -1.56024  0.40349      0.913194\n",
       "4      32229.38  0.283436    -1.301205    -1.56024  0.40349      0.913194"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_var = list(df[df.columns[0:15]].describe().columns)\n",
    "df_cont = df.loc[:, cont_var].copy()\n",
    "df_target = df['Weekly_Sales']\n",
    "df_cont.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a for-loop to look at some results for each linear regression model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use ordinary least squares in statsmodels at this stage.\n",
    "Import `statsmodels.formula.api` to get started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a loop that for each iteration:\n",
    "* Runs a simple OLS regression between (continuous) independent and dependent variables\n",
    "* Store following values in array for each iteration\n",
    "    * Target variable\n",
    "    * R_squared\n",
    "    * intercept\n",
    "    * slope\n",
    "    * p-value\n",
    "* Comment on each output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ind_var</td>\n",
       "      <td>r_square</td>\n",
       "      <td>intercept</td>\n",
       "      <td>slope</td>\n",
       "      <td>p_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Size</td>\n",
       "      <td>0.085772</td>\n",
       "      <td>17223.2</td>\n",
       "      <td>7406.23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Temperature</td>\n",
       "      <td>0.00101453</td>\n",
       "      <td>17223.2</td>\n",
       "      <td>805.483</td>\n",
       "      <td>2.16099e-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fuel_Price</td>\n",
       "      <td>0.00080294</td>\n",
       "      <td>17223.2</td>\n",
       "      <td>716.582</td>\n",
       "      <td>7.64961e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CPI</td>\n",
       "      <td>0.0394105</td>\n",
       "      <td>17223.2</td>\n",
       "      <td>-5020.31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Unemployment</td>\n",
       "      <td>0.000851711</td>\n",
       "      <td>17223.2</td>\n",
       "      <td>738.024</td>\n",
       "      <td>6.82546e-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0            1          2        3            4\n",
       "0       ind_var     r_square  intercept    slope      p_value\n",
       "1          Size     0.085772    17223.2  7406.23            0\n",
       "2   Temperature   0.00101453    17223.2  805.483  2.16099e-23\n",
       "3    Fuel_Price   0.00080294    17223.2  716.582  7.64961e-19\n",
       "4           CPI    0.0394105    17223.2 -5020.31            0\n",
       "5  Unemployment  0.000851711    17223.2  738.024  6.82546e-20"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stored = [['ind_var', 'r_square', 'intercept', 'slope', 'p_value']]\n",
    "for index, value in enumerate(['Size', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment']):\n",
    "    f = 'Weekly_Sales~' + value\n",
    "    model = smf.ols(formula = f, data = df_cont).fit()\n",
    "    \n",
    "    X_new = pd.DataFrame({value:[df_cont[value].min(), df_cont[value].max()]});\n",
    "    pred = model.predict(X_new)\n",
    "    stored.append([value, model.rsquared, model.params[0], model.params[1], model.pvalues[1]])\n",
    "\n",
    "stored_values = pd.DataFrame(stored)\n",
    "stored_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our R-square is incredibly low, which indicates little indication of expected results. It suggests we may need to transform the\n",
    "#data. P-value indicate that the independent variables do not explain results at all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think about your results. \n",
    "- What do the parameter estimates mean? Do they make sense? \n",
    "- What do the p-values tell us?\n",
    "- What does the R-squared tell us?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our R-squared values are low, let's try to solve this\n",
    "\n",
    "Something we haven't considered before, is taking log-transformations to make certain data less skewed. Let's take a quick look at our summarizing histograms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x000001EB22791470>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001EB1FD6E7F0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x000001EB13266B00>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001EB21D00E10>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x000001EB13292160>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001EB13292198>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cont.hist(figsize= (12,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly the most problematic variable in terms of skewness seems to be weekly sales itself. Does it make sense to log-transform this variable? It definitely doesn't hurt to try! Let's have a look below. what do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thien Nguyen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\Thien Nguyen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in log\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "range parameter must be finite.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-150-aa4574b22a02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_cont\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Weekly_Sales'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\plotting\\_core.py\u001b[0m in \u001b[0;36mhist_series\u001b[1;34m(self, by, ax, grid, xlabelsize, xrot, ylabelsize, yrot, figsize, bins, **kwds)\u001b[0m\n\u001b[0;32m   2479\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2481\u001b[1;33m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2482\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2483\u001b[0m         \u001b[0maxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1853\u001b[0m                         \u001b[1;34m\"the Matplotlib list!)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1854\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1855\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1856\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1857\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mhist\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   6528\u001b[0m             \u001b[1;31m# this will automatically overwrite bins,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6529\u001b[0m             \u001b[1;31m# so that each histogram uses the same bins\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6530\u001b[1;33m             \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mhist_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6531\u001b[0m             \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# causes problems later if it's an int\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6532\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmlast\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mhistogram\u001b[1;34m(a, bins, range, normed, weights, density)\u001b[0m\n\u001b[0;32m    668\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfirst_edge\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_edge\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m         raise ValueError(\n\u001b[1;32m--> 670\u001b[1;33m             'range parameter must be finite.')\n\u001b[0m\u001b[0;32m    671\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfirst_edge\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlast_edge\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m         \u001b[0mfirst_edge\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: range parameter must be finite."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.log(df_cont['Weekly_Sales']).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's right, we have some negative `Weekly_Sales` values! Let's check how many we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df_cont['Weekly_Sales'] <= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97839"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_cont['Weekly_Sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[188,\n",
       " 406,\n",
       " 2549,\n",
       " 3632,\n",
       " 4132,\n",
       " 4419,\n",
       " 4851,\n",
       " 5342,\n",
       " 5691,\n",
       " 5762,\n",
       " 6341,\n",
       " 7065,\n",
       " 7642,\n",
       " 7862,\n",
       " 7930,\n",
       " 8002,\n",
       " 8403,\n",
       " 9385,\n",
       " 10651,\n",
       " 10732,\n",
       " 10939,\n",
       " 11224,\n",
       " 12072,\n",
       " 12284,\n",
       " 12854,\n",
       " 13142,\n",
       " 13210,\n",
       " 13282,\n",
       " 13599,\n",
       " 13791,\n",
       " 14003,\n",
       " 15255,\n",
       " 15443,\n",
       " 17153,\n",
       " 17370,\n",
       " 17952,\n",
       " 18449,\n",
       " 18526,\n",
       " 18923,\n",
       " 19260,\n",
       " 19302,\n",
       " 19491,\n",
       " 21546,\n",
       " 21548,\n",
       " 23692,\n",
       " 25438,\n",
       " 25918,\n",
       " 28302,\n",
       " 28855,\n",
       " 28929,\n",
       " 29307,\n",
       " 29436,\n",
       " 31867,\n",
       " 35584,\n",
       " 36738,\n",
       " 37817,\n",
       " 38509,\n",
       " 40064,\n",
       " 40648,\n",
       " 40831,\n",
       " 41385,\n",
       " 42484,\n",
       " 43150,\n",
       " 44419,\n",
       " 44433,\n",
       " 44544,\n",
       " 44662,\n",
       " 44763,\n",
       " 44787,\n",
       " 45290,\n",
       " 45544,\n",
       " 45634,\n",
       " 46078,\n",
       " 46456,\n",
       " 47114,\n",
       " 47225,\n",
       " 48026,\n",
       " 48150,\n",
       " 48832,\n",
       " 48896,\n",
       " 49063,\n",
       " 49136,\n",
       " 49281,\n",
       " 49699,\n",
       " 49744,\n",
       " 50026,\n",
       " 51885,\n",
       " 52245,\n",
       " 52740,\n",
       " 52856,\n",
       " 52886,\n",
       " 53171,\n",
       " 55032,\n",
       " 55895,\n",
       " 56039,\n",
       " 56111,\n",
       " 56472,\n",
       " 57090,\n",
       " 58542,\n",
       " 58983,\n",
       " 60084,\n",
       " 60306,\n",
       " 61571,\n",
       " 61914,\n",
       " 62005,\n",
       " 62140,\n",
       " 62459,\n",
       " 62594,\n",
       " 62617,\n",
       " 62842,\n",
       " 62980,\n",
       " 63451,\n",
       " 63877,\n",
       " 65156,\n",
       " 65436,\n",
       " 65440,\n",
       " 65479,\n",
       " 65784,\n",
       " 67433,\n",
       " 67576,\n",
       " 67720,\n",
       " 67918,\n",
       " 68311,\n",
       " 68458,\n",
       " 70330,\n",
       " 70467,\n",
       " 71438,\n",
       " 71505,\n",
       " 72060,\n",
       " 72063,\n",
       " 73830,\n",
       " 74240,\n",
       " 74417,\n",
       " 74685,\n",
       " 75037,\n",
       " 75446,\n",
       " 78698,\n",
       " 79077,\n",
       " 79480,\n",
       " 79989,\n",
       " 80704,\n",
       " 81371,\n",
       " 81566,\n",
       " 81617,\n",
       " 81863,\n",
       " 82085,\n",
       " 82299,\n",
       " 82984,\n",
       " 83043,\n",
       " 83063,\n",
       " 83164,\n",
       " 83226,\n",
       " 84617,\n",
       " 85009,\n",
       " 85083,\n",
       " 85193,\n",
       " 85369,\n",
       " 85513,\n",
       " 85789,\n",
       " 85853,\n",
       " 86069,\n",
       " 86194,\n",
       " 86258,\n",
       " 86380,\n",
       " 86570,\n",
       " 86883,\n",
       " 86944,\n",
       " 87007,\n",
       " 87069,\n",
       " 87716,\n",
       " 87819,\n",
       " 87867,\n",
       " 87957,\n",
       " 88836,\n",
       " 88923,\n",
       " 88995,\n",
       " 89136,\n",
       " 89326,\n",
       " 89399,\n",
       " 89401,\n",
       " 89474,\n",
       " 89716,\n",
       " 89733,\n",
       " 89978,\n",
       " 90004,\n",
       " 90196,\n",
       " 90502,\n",
       " 90514,\n",
       " 90565,\n",
       " 90850,\n",
       " 91068,\n",
       " 91168,\n",
       " 91237,\n",
       " 91717,\n",
       " 91959,\n",
       " 92076,\n",
       " 92480,\n",
       " 92552,\n",
       " 92651,\n",
       " 92749,\n",
       " 92770,\n",
       " 92796,\n",
       " 93038,\n",
       " 93225,\n",
       " 93230,\n",
       " 93271,\n",
       " 93513,\n",
       " 93543,\n",
       " 93612,\n",
       " 93815,\n",
       " 94552,\n",
       " 94961,\n",
       " 95030,\n",
       " 95167,\n",
       " 95175,\n",
       " 95535,\n",
       " 95684,\n",
       " 95942,\n",
       " 96155,\n",
       " 96250,\n",
       " 96321,\n",
       " 96648,\n",
       " 97166,\n",
       " 97519]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_prices = list(df_cont[df_cont['Weekly_Sales'] <= 0].index)\n",
    "neg_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems negligibe considering we have almost 100,000 observations. Let's remove these 224 rows so we can take the log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont = df_cont.drop(neg_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97615"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_cont['Weekly_Sales'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have another look at the histogram. What do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1eb13324080>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.log(df_cont['Weekly_Sales']).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's repeat what we did before, yet now with the log(Weekly_Sales) as the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont['log_sales'] = np.log(df_cont['Weekly_Sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Size</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>log_sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24924.50</td>\n",
       "      <td>0.283436</td>\n",
       "      <td>-1.301205</td>\n",
       "      <td>-1.56024</td>\n",
       "      <td>0.40349</td>\n",
       "      <td>0.913194</td>\n",
       "      <td>10.123607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50605.27</td>\n",
       "      <td>0.283436</td>\n",
       "      <td>-1.301205</td>\n",
       "      <td>-1.56024</td>\n",
       "      <td>0.40349</td>\n",
       "      <td>0.913194</td>\n",
       "      <td>10.831811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13740.12</td>\n",
       "      <td>0.283436</td>\n",
       "      <td>-1.301205</td>\n",
       "      <td>-1.56024</td>\n",
       "      <td>0.40349</td>\n",
       "      <td>0.913194</td>\n",
       "      <td>9.528075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39954.04</td>\n",
       "      <td>0.283436</td>\n",
       "      <td>-1.301205</td>\n",
       "      <td>-1.56024</td>\n",
       "      <td>0.40349</td>\n",
       "      <td>0.913194</td>\n",
       "      <td>10.595485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32229.38</td>\n",
       "      <td>0.283436</td>\n",
       "      <td>-1.301205</td>\n",
       "      <td>-1.56024</td>\n",
       "      <td>0.40349</td>\n",
       "      <td>0.913194</td>\n",
       "      <td>10.380634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Weekly_Sales      Size  Temperature  Fuel_Price      CPI  Unemployment  \\\n",
       "0      24924.50  0.283436    -1.301205    -1.56024  0.40349      0.913194   \n",
       "1      50605.27  0.283436    -1.301205    -1.56024  0.40349      0.913194   \n",
       "2      13740.12  0.283436    -1.301205    -1.56024  0.40349      0.913194   \n",
       "3      39954.04  0.283436    -1.301205    -1.56024  0.40349      0.913194   \n",
       "4      32229.38  0.283436    -1.301205    -1.56024  0.40349      0.913194   \n",
       "\n",
       "   log_sales  \n",
       "0  10.123607  \n",
       "1  10.831811  \n",
       "2   9.528075  \n",
       "3  10.595485  \n",
       "4  10.380634  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cont.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ind_var</td>\n",
       "      <td>r_square</td>\n",
       "      <td>intercept</td>\n",
       "      <td>slope</td>\n",
       "      <td>p_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Size</td>\n",
       "      <td>0.10781</td>\n",
       "      <td>8.67149</td>\n",
       "      <td>0.611619</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Temperature</td>\n",
       "      <td>0.0007655</td>\n",
       "      <td>8.6716</td>\n",
       "      <td>0.0515691</td>\n",
       "      <td>5.34002e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fuel_Price</td>\n",
       "      <td>0.000449281</td>\n",
       "      <td>8.67161</td>\n",
       "      <td>0.0394923</td>\n",
       "      <td>3.51766e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CPI</td>\n",
       "      <td>0.0259491</td>\n",
       "      <td>8.6717</td>\n",
       "      <td>-0.300207</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Unemployment</td>\n",
       "      <td>0.000276961</td>\n",
       "      <td>8.67162</td>\n",
       "      <td>0.0310137</td>\n",
       "      <td>1.99438e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0            1          2          3            4\n",
       "0       ind_var     r_square  intercept      slope      p_value\n",
       "1          Size      0.10781    8.67149   0.611619            0\n",
       "2   Temperature    0.0007655     8.6716  0.0515691  5.34002e-18\n",
       "3    Fuel_Price  0.000449281    8.67161  0.0394923  3.51766e-11\n",
       "4           CPI    0.0259491     8.6717  -0.300207            0\n",
       "5  Unemployment  0.000276961    8.67162  0.0310137  1.99438e-07"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stored = [['ind_var', 'r_square', 'intercept', 'slope', 'p_value']]\n",
    "for index, value in enumerate(['Size', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment']):\n",
    "    f = 'log_sales~' + value\n",
    "    model = smf.ols(formula = f, data = df_cont).fit()\n",
    "    \n",
    "    X_new = pd.DataFrame({value:[df_cont[value].min(), df_cont[value].max()]});\n",
    "    pred = model.predict(X_new)\n",
    "    stored.append([value, model.rsquared, model.params[0], model.params[1], model.pvalues[1]])\n",
    "\n",
    "stored_values = pd.DataFrame(stored)\n",
    "stored_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#except for size, it seems like r_square actually decreased for other predictors. It's hard to recommend either method fully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- compare and contract the results with the results obtained when we did not take the log(sales)\n",
    "- Which one would you want to proceed with based on this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a model with each categorical variable as a predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use it on the log-transformed, and the regular `Weekly_Sales`\n",
    "- put all categories for one categorical variable in 1 model, so we want 4 models.\n",
    "- remember that we have 4 categorical variables: `Store`,  `Dept`, `IsHoliday` and `Type`( we're for now ignoring the `binned_markdown` categories, you can add then later on as an extension)\n",
    "- IMPORTANT: remember that we made dummies for `Type`, `Dept` and `Store` columns. You'll need to drop 1 column for each of these if you want good results. The reason for this is that singularity will occur and . This is related to what we mentioned earlier on in section 11. Don't worry about the \"why\" for now, just make sure to drop 1 column and you should be fine! The parameter value for the dropper \"base category\" will be absorbed in the intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thien Nguyen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           Weekly_Sales   R-squared:                       0.128\n",
      "Model:                            OLS   Adj. R-squared:                  0.128\n",
      "Method:                 Least Squares   F-statistic:                     1431.\n",
      "Date:                Fri, 23 Nov 2018   Prob (F-statistic):               0.00\n",
      "Time:                        14:00:36   Log-Likelihood:            -1.9258e+05\n",
      "No. Observations:               97615   AIC:                         3.852e+05\n",
      "Df Residuals:                   97604   BIC:                         3.853e+05\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept      6.416e+09    1.3e+11      0.049      0.961   -2.49e+11    2.62e+11\n",
      "Store_1[T.1]  -6.416e+09    1.3e+11     -0.049      0.961   -2.62e+11    2.49e+11\n",
      "Store_10[T.1] -6.416e+09    1.3e+11     -0.049      0.961   -2.62e+11    2.49e+11\n",
      "Store_2[T.1]  -6.416e+09    1.3e+11     -0.049      0.961   -2.62e+11    2.49e+11\n",
      "Store_3[T.1]  -6.416e+09    1.3e+11     -0.049      0.961   -2.62e+11    2.49e+11\n",
      "Store_4[T.1]  -6.416e+09    1.3e+11     -0.049      0.961   -2.62e+11    2.49e+11\n",
      "Store_5[T.1]  -6.416e+09    1.3e+11     -0.049      0.961   -2.62e+11    2.49e+11\n",
      "Store_6[T.1]  -6.416e+09    1.3e+11     -0.049      0.961   -2.62e+11    2.49e+11\n",
      "Store_7[T.1]  -6.416e+09    1.3e+11     -0.049      0.961   -2.62e+11    2.49e+11\n",
      "Store_8[T.1]  -6.416e+09    1.3e+11     -0.049      0.961   -2.62e+11    2.49e+11\n",
      "Store_9[T.1]  -6.416e+09    1.3e+11     -0.049      0.961   -2.62e+11    2.49e+11\n",
      "==============================================================================\n",
      "Omnibus:                    28898.116   Durbin-Watson:                   1.536\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           102000.512\n",
      "Skew:                          -1.476   Prob(JB):                         0.00\n",
      "Kurtosis:                       7.045   Cond. No.                     8.13e+13\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.63e-23. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           Weekly_Sales   R-squared:                       0.624\n",
      "Model:                            OLS   Adj. R-squared:                  0.624\n",
      "Method:                 Least Squares   F-statistic:                     2074.\n",
      "Date:                Fri, 23 Nov 2018   Prob (F-statistic):               0.00\n",
      "Time:                        14:00:37   Log-Likelihood:            -1.5153e+05\n",
      "No. Observations:               97615   AIC:                         3.032e+05\n",
      "Df Residuals:                   97536   BIC:                         3.040e+05\n",
      "Df Model:                          78                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept  -2.942e+10   1.35e+11     -0.218      0.828   -2.94e+11    2.35e+11\n",
      "Dept_1      2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_10     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_11     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_12     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_13     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_14     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_16     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_17     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_18     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_19     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_2      2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_20     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_21     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_22     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_23     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_24     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_25     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_26     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_27     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_28     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_29     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_3      2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_30     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_31     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_32     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_33     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_34     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_35     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_36     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_37     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_38     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_39     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_4      2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_40     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_41     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_42     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_44     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_45     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_46     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_47     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_48     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_49     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_5      2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_50     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_51     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_52     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_54     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_55     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_56     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_58     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_59     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_6      2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_60     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_67     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_7      2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_71     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_72     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_74     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_77     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_78     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_79     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_8      2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_80     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_81     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_82     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_83     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_85     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_87     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_9      2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_90     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_91     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_92     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_93     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_94     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_95     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_96     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_97     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_98     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "Dept_99     2.942e+10   1.35e+11      0.218      0.828   -2.35e+11    2.94e+11\n",
      "==============================================================================\n",
      "Omnibus:                    33286.217   Durbin-Watson:                   0.999\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           249009.273\n",
      "Skew:                          -1.444   Prob(JB):                         0.00\n",
      "Kurtosis:                      10.272   Cond. No.                     3.32e+14\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 8.96e-25. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           Weekly_Sales   R-squared:                       0.068\n",
      "Model:                            OLS   Adj. R-squared:                  0.068\n",
      "Method:                 Least Squares   F-statistic:                     7074.\n",
      "Date:                Fri, 23 Nov 2018   Prob (F-statistic):               0.00\n",
      "Time:                        14:00:37   Log-Likelihood:            -1.9584e+05\n",
      "No. Observations:               97615   AIC:                         3.917e+05\n",
      "Df Residuals:                   97613   BIC:                         3.917e+05\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      5.7680      0.004   1501.226      0.000       5.760       5.776\n",
      "Type_A         3.3687      0.006    561.363      0.000       3.357       3.380\n",
      "Type_B         2.3993      0.006    390.239      0.000       2.387       2.411\n",
      "==============================================================================\n",
      "Omnibus:                    24208.178   Durbin-Watson:                   1.437\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            73067.927\n",
      "Skew:                          -1.285   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.371   Cond. No.                     8.71e+15\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.93e-27. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           Weekly_Sales   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                     9.748\n",
      "Date:                Fri, 23 Nov 2018   Prob (F-statistic):            0.00180\n",
      "Time:                        14:00:37   Log-Likelihood:            -1.9925e+05\n",
      "No. Observations:               97615   AIC:                         3.985e+05\n",
      "Df Residuals:                   97613   BIC:                         3.985e+05\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "Intercept             8.6665      0.006   1401.125      0.000       8.654       8.679\n",
      "IsHoliday[T.True]     0.0727      0.023      3.122      0.002       0.027       0.118\n",
      "==============================================================================\n",
      "Omnibus:                    21883.886   Durbin-Watson:                   1.340\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            56621.948\n",
      "Skew:                          -1.220   Prob(JB):                         0.00\n",
      "Kurtosis:                       5.822   Cond. No.                         3.93\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "cols_store= df.columns[7:17]\n",
    "cols_dept = df.columns[17:96]\n",
    "cols_type = df.columns[96:98]\n",
    "cols_holiday = df.columns[1:2] \n",
    "\n",
    "df_log = df[df['Weekly_Sales']>0]\n",
    "df_log['Weekly_Sales'] = np.log(df_log['Weekly_Sales'])\n",
    "\n",
    "cols = [cols_store, cols_dept, cols_type, cols_holiday]\n",
    "for col in cols:\n",
    "    f = \"Weekly_Sales~\" + '+'.join(col)\n",
    "    model = smf.ols(formula = f, data = df_log).fit()\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           Weekly_Sales   R-squared:                       0.123\n",
      "Model:                            OLS   Adj. R-squared:                  0.123\n",
      "Method:                 Least Squares   F-statistic:                     1367.\n",
      "Date:                Fri, 23 Nov 2018   Prob (F-statistic):               0.00\n",
      "Time:                        14:01:03   Log-Likelihood:            -1.1243e+06\n",
      "No. Observations:               97839   AIC:                         2.249e+06\n",
      "Df Residuals:                   97828   BIC:                         2.249e+06\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept     -1.579e+15    1.4e+15     -1.128      0.259   -4.32e+15    1.16e+15\n",
      "Store_1[T.1]   1.579e+15    1.4e+15      1.128      0.259   -1.16e+15    4.32e+15\n",
      "Store_10[T.1]  1.579e+15    1.4e+15      1.128      0.259   -1.16e+15    4.32e+15\n",
      "Store_2[T.1]   1.579e+15    1.4e+15      1.128      0.259   -1.16e+15    4.32e+15\n",
      "Store_3[T.1]   1.579e+15    1.4e+15      1.128      0.259   -1.16e+15    4.32e+15\n",
      "Store_4[T.1]   1.579e+15    1.4e+15      1.128      0.259   -1.16e+15    4.32e+15\n",
      "Store_5[T.1]   1.579e+15    1.4e+15      1.128      0.259   -1.16e+15    4.32e+15\n",
      "Store_6[T.1]   1.579e+15    1.4e+15      1.128      0.259   -1.16e+15    4.32e+15\n",
      "Store_7[T.1]   1.579e+15    1.4e+15      1.128      0.259   -1.16e+15    4.32e+15\n",
      "Store_8[T.1]   1.579e+15    1.4e+15      1.128      0.259   -1.16e+15    4.32e+15\n",
      "Store_9[T.1]   1.579e+15    1.4e+15      1.128      0.259   -1.16e+15    4.32e+15\n",
      "==============================================================================\n",
      "Omnibus:                    71891.476   Durbin-Watson:                   1.297\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          2577944.918\n",
      "Skew:                           3.158   Prob(JB):                         0.00\n",
      "Kurtosis:                      27.341   Cond. No.                     6.43e+13\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 2.6e-23. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           Weekly_Sales   R-squared:                       0.503\n",
      "Model:                            OLS   Adj. R-squared:                  0.503\n",
      "Method:                 Least Squares   F-statistic:                     1269.\n",
      "Date:                Fri, 23 Nov 2018   Prob (F-statistic):               0.00\n",
      "Time:                        14:01:04   Log-Likelihood:            -1.0965e+06\n",
      "No. Observations:               97839   AIC:                         2.193e+06\n",
      "Df Residuals:                   97760   BIC:                         2.194e+06\n",
      "Df Model:                          78                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   1.992e+15   1.87e+15      1.067      0.286   -1.67e+15    5.65e+15\n",
      "Dept_1     -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_10    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_11    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_12    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_13    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_14    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_16    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_17    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_18    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_19    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_2     -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_20    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_21    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_22    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_23    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_24    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_25    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_26    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_27    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_28    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_29    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_3     -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_30    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_31    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_32    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_33    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_34    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_35    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_36    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_37    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_38    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_39    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_4     -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_40    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_41    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_42    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_44    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_45    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_46    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_47    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_48    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_49    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_5     -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_50    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_51    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_52    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_54    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_55    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_56    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_58    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_59    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_6     -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_60    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_67    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_7     -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_71    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_72    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_74    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_77    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_78    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_79    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_8     -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_80    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_81    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_82    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_83    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_85    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_87    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_9     -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_90    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_91    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_92    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_93    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_94    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_95    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_96    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_97    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_98    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "Dept_99    -1.992e+15   1.87e+15     -1.067      0.286   -5.65e+15    1.67e+15\n",
      "==============================================================================\n",
      "Omnibus:                    71364.001   Durbin-Watson:                   0.888\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          8933373.731\n",
      "Skew:                           2.697   Prob(JB):                         0.00\n",
      "Kurtosis:                      49.500   Cond. No.                     2.95e+14\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.14e-24. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           Weekly_Sales   R-squared:                       0.050\n",
      "Model:                            OLS   Adj. R-squared:                  0.050\n",
      "Method:                 Least Squares   F-statistic:                     5097.\n",
      "Date:                Fri, 23 Nov 2018   Prob (F-statistic):               0.00\n",
      "Time:                        14:01:04   Log-Likelihood:            -1.1282e+06\n",
      "No. Observations:               97839   AIC:                         2.256e+06\n",
      "Df Residuals:                   97837   BIC:                         2.257e+06\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   1.133e+04     52.589    215.506      0.000    1.12e+04    1.14e+04\n",
      "Type_A       1.13e+04     82.155    137.524      0.000    1.11e+04    1.15e+04\n",
      "Type_B        34.9907     84.134      0.416      0.677    -129.911     199.892\n",
      "==============================================================================\n",
      "Omnibus:                    73545.565   Durbin-Watson:                   1.197\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          2462495.982\n",
      "Skew:                           3.299   Prob(JB):                         0.00\n",
      "Kurtosis:                      26.675   Cond. No.                     2.58e+15\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 2.21e-26. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           Weekly_Sales   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                     21.05\n",
      "Date:                Fri, 23 Nov 2018   Prob (F-statistic):           4.47e-06\n",
      "Time:                        14:01:04   Log-Likelihood:            -1.1307e+06\n",
      "No. Observations:               97839   AIC:                         2.261e+06\n",
      "Df Residuals:                   97837   BIC:                         2.261e+06\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "Intercept          1.712e+04     83.851    204.184      0.000     1.7e+04    1.73e+04\n",
      "IsHoliday[T.True]  1448.6105    315.703      4.589      0.000     829.837    2067.384\n",
      "==============================================================================\n",
      "Omnibus:                    72236.950   Durbin-Watson:                   1.138\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          2092730.538\n",
      "Skew:                           3.265   Prob(JB):                         0.00\n",
      "Kurtosis:                      24.696   Cond. No.                         3.93\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "cols = [cols_store, cols_dept, cols_type, cols_holiday]\n",
    "for col in cols:\n",
    "    f = \"Weekly_Sales~\" + '+'.join(col)\n",
    "    model = smf.ols(formula = f, data = df).fit()\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's drop a few columns in our data set based on our findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's stick with our `walmart_log` data, as it seemed like it was generally resulting in higher R-squared values.\n",
    "- Let's drop continuous variables which resulted in single linear models with a R-squared value <0.01 for the `walmart_log models`.\n",
    "- Let's make sure to drop 1 column for each categorical variable we end up using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Size</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Dept_1</th>\n",
       "      <th>Dept_10</th>\n",
       "      <th>Dept_11</th>\n",
       "      <th>Dept_12</th>\n",
       "      <th>Dept_13</th>\n",
       "      <th>Dept_14</th>\n",
       "      <th>Dept_16</th>\n",
       "      <th>...</th>\n",
       "      <th>Dept_90</th>\n",
       "      <th>Dept_91</th>\n",
       "      <th>Dept_92</th>\n",
       "      <th>Dept_93</th>\n",
       "      <th>Dept_94</th>\n",
       "      <th>Dept_95</th>\n",
       "      <th>Dept_96</th>\n",
       "      <th>Dept_97</th>\n",
       "      <th>Dept_98</th>\n",
       "      <th>Type_A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>97615.000000</td>\n",
       "      <td>97615.000000</td>\n",
       "      <td>97615.000000</td>\n",
       "      <td>97615.000000</td>\n",
       "      <td>97615.000000</td>\n",
       "      <td>97615.000000</td>\n",
       "      <td>97615.000000</td>\n",
       "      <td>97615.000000</td>\n",
       "      <td>97615.000000</td>\n",
       "      <td>97615.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>97615.000000</td>\n",
       "      <td>97615.000000</td>\n",
       "      <td>97615.000000</td>\n",
       "      <td>97615.000000</td>\n",
       "      <td>97615.000000</td>\n",
       "      <td>97615.000000</td>\n",
       "      <td>97615.000000</td>\n",
       "      <td>97615.000000</td>\n",
       "      <td>97615.000000</td>\n",
       "      <td>97615.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.671603</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.014649</td>\n",
       "      <td>0.014649</td>\n",
       "      <td>0.014649</td>\n",
       "      <td>0.014649</td>\n",
       "      <td>0.014649</td>\n",
       "      <td>0.014649</td>\n",
       "      <td>0.014649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014649</td>\n",
       "      <td>0.014649</td>\n",
       "      <td>0.014649</td>\n",
       "      <td>0.010275</td>\n",
       "      <td>0.011453</td>\n",
       "      <td>0.014649</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>0.013072</td>\n",
       "      <td>0.010572</td>\n",
       "      <td>0.520197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.863225</td>\n",
       "      <td>1.000262</td>\n",
       "      <td>0.999782</td>\n",
       "      <td>0.120145</td>\n",
       "      <td>0.120145</td>\n",
       "      <td>0.120145</td>\n",
       "      <td>0.120145</td>\n",
       "      <td>0.120145</td>\n",
       "      <td>0.120145</td>\n",
       "      <td>0.120145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120145</td>\n",
       "      <td>0.120145</td>\n",
       "      <td>0.120145</td>\n",
       "      <td>0.100844</td>\n",
       "      <td>0.106405</td>\n",
       "      <td>0.120145</td>\n",
       "      <td>0.113275</td>\n",
       "      <td>0.113583</td>\n",
       "      <td>0.102277</td>\n",
       "      <td>0.499594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.605170</td>\n",
       "      <td>-1.611999</td>\n",
       "      <td>-1.958762</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.766504</td>\n",
       "      <td>-1.028620</td>\n",
       "      <td>-0.126697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.948477</td>\n",
       "      <td>0.283436</td>\n",
       "      <td>0.499521</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.948167</td>\n",
       "      <td>1.113495</td>\n",
       "      <td>0.635046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13.448929</td>\n",
       "      <td>1.171380</td>\n",
       "      <td>0.851771</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Weekly_Sales          Size           CPI        Dept_1       Dept_10  \\\n",
       "count  97615.000000  97615.000000  97615.000000  97615.000000  97615.000000   \n",
       "mean       8.671603      0.000193      0.000335      0.014649      0.014649   \n",
       "std        1.863225      1.000262      0.999782      0.120145      0.120145   \n",
       "min       -4.605170     -1.611999     -1.958762      0.000000      0.000000   \n",
       "25%        7.766504     -1.028620     -0.126697      0.000000      0.000000   \n",
       "50%        8.948477      0.283436      0.499521      0.000000      0.000000   \n",
       "75%        9.948167      1.113495      0.635046      0.000000      0.000000   \n",
       "max       13.448929      1.171380      0.851771      1.000000      1.000000   \n",
       "\n",
       "            Dept_11       Dept_12       Dept_13       Dept_14       Dept_16  \\\n",
       "count  97615.000000  97615.000000  97615.000000  97615.000000  97615.000000   \n",
       "mean       0.014649      0.014649      0.014649      0.014649      0.014649   \n",
       "std        0.120145      0.120145      0.120145      0.120145      0.120145   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           ...            Dept_90       Dept_91       Dept_92       Dept_93  \\\n",
       "count      ...       97615.000000  97615.000000  97615.000000  97615.000000   \n",
       "mean       ...           0.014649      0.014649      0.014649      0.010275   \n",
       "std        ...           0.120145      0.120145      0.120145      0.100844   \n",
       "min        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "25%        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "50%        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "75%        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "max        ...           1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "            Dept_94       Dept_95       Dept_96       Dept_97       Dept_98  \\\n",
       "count  97615.000000  97615.000000  97615.000000  97615.000000  97615.000000   \n",
       "mean       0.011453      0.014649      0.013000      0.013072      0.010572   \n",
       "std        0.106405      0.120145      0.113275      0.113583      0.102277   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "             Type_A  \n",
       "count  97615.000000  \n",
       "mean       0.520197  \n",
       "std        0.499594  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        1.000000  \n",
       "75%        1.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 82 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = df_log.drop(['Fuel_Price', 'Unemployment', 'Temperature', 'IsHoliday', 'Store_9', 'Dept_99', 'Type_B'], axis = 1)\n",
    "bin_markdown = df_final.columns[91:121]\n",
    "df_final = df_final.drop(bin_markdown, axis =1)\n",
    "df_final.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From here on out, use Feature ranking with recursive feature elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a matrix X and y containing the predictors and target for our model. Let's use Scikit-Learn's RFE function, documentation again [here](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_final.drop(['Weekly_Sales'], axis = 1)\n",
    "y = df_final['Weekly_Sales']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a for loop using `RFE` where we look at the 5, 15, 25,... up until 85 best features to be selected according to the feature ranking algorithm. Store the R-squared and the adjusted-R-squareds for all these models in a list. What do you see? No need to perform a train-test-split for now- that will be next!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07796309689788572, 0.12789434193206628, 0.19911453243792243, 0.2873214586265447, 0.3476968603928441, 0.40407422116714775, 0.4549808400890991, 0.49682388000800015, 0.5385924896419778, 0.5766347031447792, 0.6085866558513449, 0.6433571577574093, 0.6616513307277998, 0.6822566675501762, 0.7109624169739837, 0.7498891328971407, 0.7715442558757626]\n",
      "[0.07711219536309233, 0.1270895194347722, 0.19837543547634806, 0.2866637634056389, 0.34709488259697185, 0.4035242712051389, 0.4544778692881478, 0.49635952404639805, 0.5381666798317545, 0.576244000582159, 0.6082254401406133, 0.6430280299960189, 0.6613390857395456, 0.6819634381920645, 0.71069567870984, 0.7496583181434466, 0.7713334255471134]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "r = []\n",
    "adj_r=[]\n",
    "linreg = LinearRegression()\n",
    "n_list = range(5,86,5)\n",
    "for n in n_list:\n",
    "    selector = RFE(linreg, n_features_to_select = n)\n",
    "    selector = selector.fit(X,y)\n",
    "    sel_column = X.columns[selector.support_]\n",
    "    linreg.fit(X[sel_column], y)\n",
    "    yhat = linreg.predict(X[sel_column])\n",
    "    SSR = np.sum((y - yhat)**2)\n",
    "    SST = np.sum((y - np.mean(y))**2)\n",
    "    R2 = 1 - (SSR/SST)\n",
    "    R2_adj = 1 - (1-R2)*(len(y)-1)/(len(y)-len(X.columns)-1)\n",
    "    r.append(R2)\n",
    "    adj_r.append(R2_adj)\n",
    "\n",
    "print(r)\n",
    "print(adj_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between $R^2$ and adjusted $R^2$ is negligible, and seems to continue to be going up as we include more features. Remember though that we're likely overfitting when including 85 features. In order to identify this, let's rerun a similar experiment, but using a train test split!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Including a train-test-split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a similar for loop to what we did before. Except, this time\n",
    "- Use a train test split of 20-80\n",
    "- Instead of looking at $R^2$ and $R^2_{adj}$, look at the MSE for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6550603225863158e-31\n",
      "7.943662174574883\n",
      "0.0001117534625438676\n",
      "4.376350211818281\n",
      "1.965591343645671e-05\n",
      "2.5490804338275344\n",
      "9.873026103272815e-06\n",
      "1.3575691092844477\n",
      "6.019113329089471e-06\n",
      "0.007704979424419854\n",
      "2.2025043222226318e-05\n",
      "0.5440819174224492\n",
      "3.6632716177719803e-06\n",
      "0.4196610570127679\n",
      "1.772408231989313e-05\n",
      "1.3694653912583896\n",
      "1.6338121125771573e-07\n",
      "1.6659536822954242\n",
      "1.5245993693434883e-06\n",
      "1.6322532777245005\n",
      "2.620513090887177e-05\n",
      "3.242164262484157\n",
      "0.0009823764818642268\n",
      "2.0469498072736068\n",
      "1.660728339248834e-05\n",
      "2.120151241738648\n",
      "0.00021996531430347403\n",
      "1.1990892820463852\n",
      "0.000597987703741424\n",
      "1.1889934100733095\n",
      "1.998981420203523e-05\n",
      "0.3926240207616072\n",
      "7.503016932464879e-10\n",
      "0.21708484297785338\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2)\n",
    "\n",
    "mse_train_list = []\n",
    "mse_test_list = []\n",
    "list_n = range(5,86,5)\n",
    "for n in list_n:\n",
    "    selector = RFE(linreg, n_features_to_select = n)\n",
    "    selector = selector.fit(X_train, y_train)\n",
    "    sel_col = X.columns[selector.support_]\n",
    "    linreg.fit(X_train[sel_col], y_train)\n",
    "    yhat_train = linreg.predict(X_train[sel_col])\n",
    "    yhat_test = linreg.predict(X_test[sel_col])\n",
    "    mse_train = np.sum(yhat_train - y_train)**2/len(y_train)\n",
    "    print(mse_train)\n",
    "    mse_test = np.sum(yhat_test - y_test)**2/len(y_test)\n",
    "    print(mse_test)\n",
    "mse_train_list.append(mse_train)\n",
    "mse_test_list.append(mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we see is that both MSE keeps improving when we add variables. It seems like a bigger model improves our performance, and the test and train performance don't really diverge. It is important to note however that is not an unusual result. The performance measures used typically will show this type of behavior. In order to really be able to balance the curse of dimensionality (which will become more important in machine learning), we need other information criteria such as AIC and BIC. You'll learn about them later! Now, let's perform cross-validation on our model with 85 predictors!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-fold cross validation with the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a 10-fold cross-validation and store the (negative) MSEs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7.88544602e-01 -7.23190997e-01 -1.07320282e+00 -7.15431577e-01\n",
      " -1.26796352e+24 -5.57862928e-01 -1.06904444e+00 -6.12759295e-01\n",
      " -2.78004990e+21 -1.61607376e+00]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_10 = cross_val_score(linreg, X, y, cv =10, scoring = 'neg_mean_squared_error')\n",
    "print(cv_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running our 10-fold cross-validation highlights some issues for sure! Have a look at your list of 10 MSEs. Where most MSEs are manageable, some are very high. The cure of dimensionality is already pretty clear here. The issue is that we have many (dummy) categorical variables that result in columns with many zeroes and few ones. This means that for some folds, there is a risk of ending up with columns that almost exclusively contain 0's for prediction, which might cause weird results. Looking at this, a model with less predictors might make sense again. This is where we conclude for now. It's up to you now to explore other model options! Additionally, it is encouraged to try some of the \"level up\" exercises below. Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level up - Optional\n",
    "\n",
    "\n",
    "- You could argue that **throwing out negative sales figures is problematic**, because these are probably the types of observations a stakeholder would be very interested in knowing. Repeat your analysis, but now, instead of removing the rows with negative sales, replace their sales with a slightly positive value (eg. 1), so they have an existing and finite value. Does the result change?\n",
    "\n",
    "- Go back and log-transform `CPI` and `Size` before standardizing it (we did this a few lessons ago). Look at the histogram and see if there is an improvement.\n",
    "- You might have noticed we ignored `binned_markdown` throughout. Add it in the model and see how it changes the results!\n",
    "\n",
    "- Try other feature selection methods such as stepwise selection and forward selection seen in section 11.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you made it to the end of the last section in this module. Now it's time for a big project on multiple linear regression!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
